from typing import SupportsFloat, Any
import os
import numpy as np
import gymnasium as gym

from scheduler.config.settings import MAX_OBS_SIZE
from scheduler.rl_model.agents.gin_agent.mapper import GinAgentMapper
from scheduler.rl_model.core.env.action import EnvAction
from scheduler.rl_model.core.env.observation import EnvObservation
from scheduler.rl_model.core.utils.helpers import active_energy_consumption_per_mi
from scheduler.rl_model.agents.gin_agent.shared_debug import get_last_action_probs


class GinAgentWrapper(gym.Wrapper):
    observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(MAX_OBS_SIZE,), dtype=np.float32)
    action_space = gym.spaces.Discrete(MAX_OBS_SIZE)

    prev_obs: EnvObservation
    initial_obs: EnvObservation

    def __init__(self, env: gym.Env[np.ndarray, int]):
        super().__init__(env)
        self.mapper = GinAgentMapper(MAX_OBS_SIZE)
        # Terminal energy normalization state
        self.energy_ref: float | None = None  # running reference for total_energy (EMA)
        self.energy_ref_alpha: float = 0.9    # higher -> slower update
        self.terminal_energy_weight: float = 1.0
        # Weights for multi-objective reward
        self.energy_weight: float = 1.0
        self.makespan_weight: float = 1.0  # small penalty on makespan changes
        # Debug flag (enable by setting env var GIN_DEBUG=1)
        self.debug: bool = os.environ.get("GIN_DEBUG", "0") == "1"

    def reset(
        self, *, seed: int | None = None, options: dict[str, Any] | None = None
    ) -> tuple[np.ndarray, dict[str, Any]]:
        obs, info = super().reset(seed=seed, options=options)
        assert isinstance(obs, EnvObservation)
        mapped_obs = self.map_observation(obs)

        self.prev_obs = obs
        self.initial_obs = obs
        return mapped_obs, info

    def step(self, action: int) -> tuple[np.ndarray, SupportsFloat, bool, bool, dict[str, Any]]:
        # Map to (task_id, vm_id)
        vm_count = len(self.prev_obs.vm_observations)
        task_id = int(action // vm_count)
        vm_id = int(action % vm_count)
        # Validate against READY ∧ NOT-SCHEDULED ∧ COMPATIBLE
        ready = False
        not_scheduled = False
        if 0 <= task_id < len(self.prev_obs.task_observations):
            t = self.prev_obs.task_observations[task_id]
            ready = bool(t.is_ready)
            not_scheduled = (t.assigned_vm_id is None)
        compat = (task_id, vm_id) in set(self.prev_obs.compatibilities)
        if not (ready and not_scheduled and compat):
            if self.debug:
                total_compat = len(self.prev_obs.compatibilities)
                ready_cnt = sum(int(t.is_ready and (t.assigned_vm_id is None)) for t in self.prev_obs.task_observations)
                # Build the set/list of compatible VMs for this task
                compat_list = [(t_id, v_id) for (t_id, v_id) in self.prev_obs.compatibilities if t_id == task_id]
                compat_vm_ids = [v for (_t, v) in compat_list]
                has_any_compat = len(compat_vm_ids) > 0
                # Detailed diagnostics for the incompatible pair (debug only)
                try:
                    t_obs = self.prev_obs.task_observations[task_id]
                    v_obs = self.prev_obs.vm_observations[vm_id]
                    print(
                        f"[WRAPPER] INVALID proposed (t={task_id},v={vm_id}) ready={ready} not_scheduled={not_scheduled} compat={compat} | ready_cnt={ready_cnt} compat_pairs={total_compat}\n"
                        f"  Task requirements -> cores={getattr(t_obs, 'req_cpu_cores', 'N/A')}, mem_mb={getattr(t_obs, 'req_memory_mb', 'N/A')}\n"
                        f"  VM capacity      -> cores={getattr(v_obs, 'cpu_cores', 'N/A')}, mem_mb={getattr(v_obs, 'memory_mb', 'N/A')}\n"
                        f"  Task has compatible VMs? {has_any_compat} ; count={len(compat_vm_ids)} ; sample={compat_vm_ids[:10]}"
                    )
                    # Print action probability of proposed (t, v) and top-5 overall
                    probs = get_last_action_probs()
                    if probs is not None and isinstance(probs, np.ndarray):
                        T = len(self.prev_obs.task_observations)
                        V = len(self.prev_obs.vm_observations)
                        flat_idx = task_id * V + vm_id
                        p = float(probs[flat_idx]) if 0 <= flat_idx < probs.size else float('nan')
                        print(f"  Prob(proposed t={task_id}, v={vm_id}) = {p:.6g}")
                        # Top-5
                        try:
                            topk = min(5, probs.size)
                            top_idx = np.argsort(probs)[-topk:][::-1]
                            lines = []
                            for i in top_idx:
                                t_i = int(i // V)
                                v_i = int(i % V)
                                lines.append(f"    idx={int(i)} -> (t={t_i}, v={v_i}) p={float(probs[i]):.6g}")
                            print("  Top-5 actions by prob:\n" + "\n".join(lines))
                        except Exception:
                            pass
                except Exception:
                    print(
                        f"[WRAPPER] INVALID proposed (t={task_id},v={vm_id}) ready={ready} not_scheduled={not_scheduled} compat={compat} | ready_cnt={ready_cnt} compat_pairs={total_compat}"
                    )
            # Remap: pick first valid pair
            remapped = False
            compat_set = set(self.prev_obs.compatibilities)
            for t_id, tobs in enumerate(self.prev_obs.task_observations):
                if not tobs.is_ready or (tobs.assigned_vm_id is not None):
                    continue
                for v_id in range(vm_count):
                    if (t_id, v_id) in compat_set:
                        task_id, vm_id = t_id, v_id
                        remapped = True
                        break
                if remapped:
                    break
            if self.debug:
                if remapped:
                    print(f"[GIN_DEBUG][wrapper] REMAP -> (t={task_id},v={vm_id})")
                else:
                    print(f"[GIN_DEBUG][wrapper] NO VALID REMAP; using original (t={task_id},v={vm_id})")
        mapped_action = self.map_action(task_id * vm_count + vm_id)
        obs, _, terminated, truncated, info = super().step(mapped_action)
        assert isinstance(obs, EnvObservation)
        # If this is a wait observation, propagate zero reward and update prev_obs to avoid large next-step deltas
        if info.get('skip_step', False) or getattr(obs, 'is_wait', False):
            # print(f'In wrapper step: Skipping step (wait observation), returning mapped observation with zero reward')
            mapped_obs = self.map_observation(obs)
            self.prev_obs = obs
            return mapped_obs, 0.0, terminated, truncated, info
        # print(f'In wrapper step: action={mapped_action}, terminated={terminated}, truncated={truncated}')

        mapped_obs = self.map_observation(obs)

        eps = 1e-8
        # Lightweight makespan term: penalize increases in makespan, reward decreases, normalized
        makespan_reward = -(obs.makespan() - self.prev_obs.makespan()) / max(obs.makespan(), eps)
        # energy_reward = -(obs.energy_consumption() - self.prev_obs.energy_consumption()) / max(obs.energy_consumption(), eps)
        # alpha=
        # reward = self.energy_weight * energy_reward + self.makespan_weight * makespan_reward
        reward = self.makespan_weight * makespan_reward
        # Add terminal energy component: adaptively normalized (no clipping)
        # if (terminated or truncated) and isinstance(info, dict) and ("total_energy" in info):
            # total_energy = float(info["total_energy"])  # Joules (active + idle)
            # if self.energy_ref is None:
            #     # Initialize reference on first episode end
            #     self.energy_ref = max(total_energy, 1e-6)
            # else:
            #     # EMA update for stability across episodes
            #     self.energy_ref = (
            #         self.energy_ref_alpha * self.energy_ref + (1.0 - self.energy_ref_alpha) * max(total_energy, 1e-6)
            #     )
            # # Negative sign: higher energy -> more negative reward
            # terminal_term = - total_energy / max(self.energy_ref, 1e-6)
            # reward += self.terminal_energy_weight * terminal_term

        #     print(
        #         f'In wrapper step (terminal): total_energy={total_energy:.3f}, energy_ref={self.energy_ref:.3f}, '
        #         f'terminal_term={terminal_term:.4f}, weight={self.terminal_energy_weight}'
        #     )
        #     print(f'In wrapper step (terminal): makespan_reward={makespan_reward}, energy_reward={energy_reward}, total_reward={reward}')
        #
        # print(f'In wrapper step: makespan_reward={makespan_reward}, energy_reward={energy_reward}, total_reward={reward}')
        self.prev_obs = obs
        return mapped_obs, reward, terminated, truncated, info

    def map_action(self, action: int) -> EnvAction:
        vm_count = len(self.prev_obs.vm_observations)
        return EnvAction(task_id=int(action // vm_count), vm_id=int(action % vm_count))

    def map_observation(self, observation: EnvObservation) -> np.ndarray:
        # Task observations
        task_state_scheduled = np.array([task.assigned_vm_id is not None for task in observation.task_observations])
        task_state_ready = np.array([task.is_ready for task in observation.task_observations])
        task_length = np.array([task.length for task in observation.task_observations])
        task_memory_req_mb = np.array([task.req_memory_mb for task in observation.task_observations])
        task_cpu_req_cores = np.array([task.req_cpu_cores for task in observation.task_observations])

        # VM observations
        vm_speed = np.array([vm.cpu_speed_mips for vm in observation.vm_observations])
        vm_energy_rate = np.array([active_energy_consumption_per_mi(vm) for vm in observation.vm_observations])
        vm_completion_time = np.array([vm.completion_time for vm in observation.vm_observations])
        vm_memory_mb = np.array([vm.memory_mb for vm in observation.vm_observations])
        vm_available_memory_mb = np.array([vm.available_memory_mb for vm in observation.vm_observations])
        # New VM features
        vm_active_tasks_count = np.array([vm.active_tasks_count for vm in observation.vm_observations])
        # Guard against division by zero if any VM has 0 memory (shouldn't happen but safe)
        vm_used_memory_fraction = 1.0 - (vm_available_memory_mb / np.maximum(vm_memory_mb, 1e-8))
        vm_next_release_time = np.array([vm.next_release_time for vm in observation.vm_observations])
        vm_cpu_cores = np.array([vm.cpu_cores for vm in observation.vm_observations])
        vm_available_cpu_cores = np.array([vm.available_cpu_cores for vm in observation.vm_observations])
        vm_used_cpu_fraction_cores = np.array([vm.used_cpu_fraction_cores for vm in observation.vm_observations])
        vm_next_core_release_time = np.array([vm.next_core_release_time for vm in observation.vm_observations])

        # Task-Task observations
        task_dependencies = np.array(observation.task_dependencies).T

        # Task-VM observations
        compatibilities = np.array(observation.compatibilities).T

        # Task completion times
        task_completion_time = observation.task_completion_time()
        assert task_completion_time is not None

        return self.mapper.map(
            task_state_scheduled=task_state_scheduled,
            task_state_ready=task_state_ready,
            task_length=task_length,
            task_completion_time=task_completion_time,
            task_memory_req_mb=task_memory_req_mb,
            task_cpu_req_cores=task_cpu_req_cores,
            vm_speed=vm_speed,
            vm_energy_rate=vm_energy_rate,
            vm_completion_time=vm_completion_time,
            vm_memory_mb=vm_memory_mb,
            vm_available_memory_mb=vm_available_memory_mb,
            vm_used_memory_fraction=vm_used_memory_fraction,
            vm_active_tasks_count=vm_active_tasks_count,
            vm_next_release_time=vm_next_release_time,
            vm_cpu_cores=vm_cpu_cores,
            vm_available_cpu_cores=vm_available_cpu_cores,
            vm_used_cpu_fraction_cores=vm_used_cpu_fraction_cores,
            vm_next_core_release_time=vm_next_core_release_time,
            task_dependencies=task_dependencies,
            compatibilities=compatibilities,
        )
