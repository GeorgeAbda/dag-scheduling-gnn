% ============================================================================
% WASSERSTEIN GRADIENT DOMAIN DISCOVERY (WGDD)
% A Novel Unsupervised Method for Multi-Objective RL Domain Discovery
% ============================================================================

\section{Unsupervised Domain Discovery via Gradient Distributions}

A central challenge in multi-objective reinforcement learning (MORL) is identifying when different environment configurations induce fundamentally different trade-off structures. Prior work assumes domain labels are known a priori or relies on performance-based clustering after training multiple specialists. We propose \textbf{Wasserstein Gradient Domain Discovery (WGDD)}, an unsupervised method that discovers strategy domains by analyzing how a generalist policy's gradients distribute across objective weightings.

\subsection{Problem Setting}

Consider a set of MDPs $\{\mathcal{M}_i\}_{i=1}^N$ drawn from a continuous parameter space (e.g., DAG structure, resource heterogeneity). Each MDP admits a multi-objective reward $r(s,a) = -\alpha \cdot f_1(s,a) - (1-\alpha) \cdot f_2(s,a)$ for objectives $f_1$ (makespan) and $f_2$ (energy). The goal is to partition MDPs into domains $\mathcal{D}_1, \ldots, \mathcal{D}_K$ such that MDPs within a domain exhibit similar gradient responses to objective trade-offs, without access to ground-truth domain labels.

\subsection{Method}

WGDD operates in five stages:

\paragraph{1. Generalist Pre-training.}
Train a single policy $\pi_\theta$ on a mixture of MDPs sampled uniformly from the parameter space. This ensures the policy has broad experience and non-trivial gradients across diverse configurations. We use PPO with $2\times 10^6$ steps on a 50/50 mixture of Wide and LongCP workflows.

\paragraph{2. Multi-Scale Objective Sampling.}
For each MDP $\mathcal{M}_i$, we compute policy gradients under $K$ objective weightings:
\begin{itemize}
    \item \textbf{Extremes}: $\alpha \in \{0, 1\}$ (pure objectives)
    \item \textbf{Uniform}: $\alpha \sim \text{Uniform}(0.05, 0.95)$
    \item \textbf{Focused}: $\alpha \in \{0.25 \pm \epsilon, 0.5 \pm \epsilon, 0.75 \pm \epsilon\}$ for $\epsilon = 0.05$
\end{itemize}
This multi-scale sampling captures both extreme behaviors and nuanced trade-off regions.

\paragraph{3. Gradient Distribution Collection.}
For each (MDP, objective) pair, we collect $R$ gradient samples via REINFORCE:
\[
g_i^{(\alpha, r)} = \nabla_\theta \sum_t \log \pi_\theta(a_t | s_t) \cdot G_t^{(\alpha)}, \quad r = 1, \ldots, R
\]
where $G_t^{(\alpha)}$ is the return under weighting $\alpha$. This yields a distribution of gradients per MDP-objective pair, capturing stochasticity from both the environment and policy.

\paragraph{4. Wasserstein Distance Matrix.}
We measure similarity between MDPs using the Wasserstein distance between their gradient distributions. For MDPs $\mathcal{M}_i$ and $\mathcal{M}_j$:
\[
d_{ij} = \frac{1}{K} \sum_{\alpha \in \mathcal{A}} \frac{1}{D} \sum_{d=1}^{D} W_1\left( P_{i,\alpha}^{(d)}, P_{j,\alpha}^{(d)} \right)
\]
where $P_{i,\alpha}^{(d)}$ is the marginal distribution of the $d$-th PCA component of gradients for MDP $i$ under objective $\alpha$, and $W_1$ denotes the 1-Wasserstein distance. PCA projection ($D \approx 10$ components explaining $>80\%$ variance) ensures stable distance computation in high-dimensional gradient space.

\paragraph{5. Spectral Clustering with Automatic $k$ Selection.}
Convert distances to affinities via $A_{ij} = \exp(-d_{ij}^2 / 2\sigma^2)$ where $\sigma$ is the median distance. Apply spectral clustering and select $k^*$ maximizing silhouette score:
\[
k^* = \arg\max_{k \in \{2, \ldots, K_{\max}\}} \text{Silhouette}(d, \text{labels}_k)
\]

\subsection{Auxiliary Analyses}

\paragraph{Conflict Tensor.}
For interpretability, we compute pairwise gradient conflicts:
\[
C_i^{(\alpha, \beta)} = \cos\left( \bar{g}_i^{(\alpha)}, \bar{g}_i^{(\beta)} \right)
\]
where $\bar{g}_i^{(\alpha)}$ is the mean gradient for MDP $i$ under $\alpha$. The conflict between pure objectives ($\alpha=1, \beta=0$) indicates whether the MDP exhibits a true Pareto trade-off.

\paragraph{Bootstrap Stability.}
We assess clustering robustness via bootstrap resampling: subsample 80\% of MDPs, re-cluster, and track co-occurrence frequencies. The stability score $S = \mathbb{E}[\mathbf{1}[\text{same cluster}]]$ over pairs quantifies reliability.

\subsection{Experimental Results}

We evaluate WGDD on $N=40$ workflow MDPs (20 Wide, 20 LongCP) using a generalist trained on mixed data. Configuration: $K=20$ objectives, $R=5$ replicates, 256 rollout steps, 20 bootstrap iterations.

\begin{table}[t]
\centering
\caption{WGDD clustering results on workflow scheduling MDPs.}
\label{tab:wgdd-results}
\begin{tabular}{@{}lc@{}}
\toprule
Metric & Value \\
\midrule
Optimal $k$ (auto-selected) & 2 \\
NMI (vs.\ true labels) & \textbf{1.000} \\
ARI (vs.\ true labels) & \textbf{1.000} \\
Silhouette Score & 0.666 \\
Bootstrap Stability & 0.92 \\
PCA Explained Variance & 74.7\% \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key Findings.}
\begin{itemize}
    \item WGDD perfectly recovers the Wide/LongCP partition without access to labels (NMI=1.0, ARI=1.0).
    \item Automatic $k$ selection correctly identifies $k^*=2$ domains.
    \item High bootstrap stability (0.92) confirms robustness to MDP sampling.
    \item Conflict analysis reveals Wide MDPs have higher objective alignment (mean $C^{(0,1)} = 0.3$), while LongCP MDPs exhibit stronger conflict (mean $C^{(0,1)} = -0.2$).
\end{itemize}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{experiments/gradient_domain_discovery/figures/wgdd_main_results.png}
    \caption{WGDD results: (a) Wasserstein distance matrix showing block structure, (b) discovered clusters vs.\ edge probability, (c) silhouette scores for $k$ selection, (d) Pareto alignment by MDP structure.}
    \label{fig:wgdd-main}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{experiments/gradient_domain_discovery/figures/wgdd_embedding.png}
    \caption{t-SNE embedding of Wasserstein distances colored by (left) predicted clusters and (right) true labels, showing clear separation.}
    \label{fig:wgdd-embedding}
\end{figure}

\subsection{Comparison to Baseline Methods}

\begin{table}[t]
\centering
\caption{Comparison of domain discovery methods.}
\label{tab:method-comparison}
\begin{tabular}{@{}lccc@{}}
\toprule
Method & NMI & Requires Labels & Auto-$k$ \\
\midrule
Random clustering & 0.00 & No & No \\
Cosine conflict (random agent) & 0.05 & No & No \\
Cosine conflict (trained agent) & 0.52 & No & No \\
Gradient subspace (PCA + k-means) & 1.00 & No & No \\
\textbf{WGDD (ours)} & \textbf{1.00} & No & \textbf{Yes} \\
\bottomrule
\end{tabular}
\end{table}

WGDD matches the best NMI while adding automatic $k$ selection and bootstrap stability guarantees. The Wasserstein formulation captures distributional differences that point estimates (mean gradients) may miss, providing a more principled foundation for domain discovery.

\subsection{Discussion}

WGDD demonstrates that gradient distributions encode sufficient information to discover latent domain structure in MORL problems. The method requires only a generalist policy trained on mixed data, no domain labels, and automatically determines the number of domains. This enables practitioners to identify when specialist policies are needed and which environment configurations should be grouped for training.

\paragraph{Limitations.}
Computational cost scales with $O(N^2 \cdot K \cdot R)$ gradient computations. For very large MDP sets, subsampling or landmark-based approximations may be necessary. The method assumes the generalist has sufficient coverage; poorly trained generalists may yield uninformative gradients.

\paragraph{Future Work.}
Extending WGDD to more than two objectives, incorporating task embeddings alongside gradients, and deploying discovered domains for curriculum learning or mixture-of-experts training.
